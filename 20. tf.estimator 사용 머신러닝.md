# tf.estimator를 이용한 Gradient Boosting 모델 학습
> Boosted Trees 모델은 회귀 및 분류 모두에서 가장 인기있고 효과적인 머신러닝 학습 방법이다. <br/>
> 여러(10, 100 또는 1000)개의 트리 모델의 예측을 결합하는 **앙상블 기술**

### 라이브러리 및 랜덤시드 선언
```python
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

tf.random.set_seed(123)
```
<br/>

### 데이터 불러오기 및 feature/label 분류
> 다양한 방법으로 데이터를 확인 할 수 있는데, pandas 데이터 확인 방법은 [여기](https://github.com/freemancho1/ai/blob/master/04.-3.%20pandas.md#pandas-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EC%86%8C%EA%B0%9C)를 참고하면 된다.
```python
train_df = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
valid_df = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
train_df.head()
```
```python
y_train = train_df.pop('survived')  # feature 항목에서 label값을 뽑아낸다. 
y_valid = valid_df.pop('survived')  # (feature에는 이제 label이 존재하지 않는다.)
train_df.head()
```
<br/>

### 분류형 컬럼(one-hot encoding 변환) 등 속성컬럼 재생성
```python
CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
    return tf.feature_column.indicator_column(
        tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))

feature_columns = []
for cc in CATEGORICAL_COLUMNS:
    vocabulary = train_df[cc].unique()
    feature_columns.append(one_hot_cat_column(cc, vocabulary))
    
for nc in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(nc, dtype=tf.float32))
```    
<br/>

### (번외) DataFrame값을 one-hot encoding된 numpy.ndarray로 변환
> 이 부분은 다른 머신러닝 모델 학습에서도 유용하게 사용 가능할 것으로 판단됨.
```python
examples = tf.keras.layers.DenseFeatures(feature_columns)(dict(train_df)).numpy()
print(examples)

## 결과
array([[22.,  1.,  0., ...,  0.,  1.,  0.],
       [38.,  1.,  0., ...,  0.,  0.,  1.],
       [26.,  0.,  1., ...,  0.,  0.,  1.],
       ...,
       [19.,  0.,  1., ...,  0.,  0.,  1.],
       [28.,  1.,  0., ...,  0.,  0.,  1.],
       [32.,  0.,  1., ...,  0.,  1.,  0.]], dtype=float32)
```
<br/>

### 모델학습에 사용할 입력함수 만들기
> 데이터 입력 부분을 텐서플로에서 제어하기 때문에 나중에 멀티GPU 등에서 어떻게 동작하는지 확인 필요
```python
NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=True):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
        if shuffle:
            dataset = dataset.shuffle(NUM_EXAMPLES)
        # training시에 데이터셋을 필요한 만큼 순환함.
        dataset = dataset.repeat(n_epochs)
        # 데이터를 메모리에 적제한 후 시행하는 training에는 배치작업을 하지 않음.
        dataset = dataset.batch(NUM_EXAMPLES)
        return dataset
    return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(train_df, y_train)
valid_input_fn = make_input_fn(valid_df, y_valid, shuffle=False, n_epochs=1)
```
<br/>

### 비교를 위해 먼저 선형분류기인 로지스틱회귀 알고리즘을 이용한 모델 훈련 및 검증
```python
linear_est = tf.estimator.LinearClassifier(feature_columns)   # 모델 선언
linear_est.train(train_input_fn, max_steps=100)               # 모델 학습
linear_est_result = linear_est.evaluate(valid_input_fn)       # 모델 검증

print(pd.Series(linear_est_result))
## 결과
accuracy                  0.765152
accuracy_baseline         0.625000
auc                       0.832844
auc_precision_recall      0.789631
average_loss              0.478908
label/mean                0.375000
loss                      0.478908
precision                 0.703297
prediction/mean           0.350790
recall                    0.646465
global_step             100.000000
dtype: float64
```
> 76.5% 정확도

<br/>

### Boosted Tree를 이용한 모델 훈련 및 검증
```python
n_batches = 1
boosted_est = tf.estimator.BoostedTreesClassifier(feature_columns, n_batches_per_layer=n_batches)
boosted_est.train(train_input_fn, max_steps=100)
boosted_est_result = boosted_est.evaluate(valid_input_fn)

print(pd.Series(boosted_est_result))
## 결과
accuracy                  0.837121
accuracy_baseline         0.625000
auc                       0.871993
auc_precision_recall      0.858760
average_loss              0.406563
label/mean                0.375000
loss                      0.406563
precision                 0.797872
prediction/mean           0.384452
recall                    0.757576
global_step             100.000000
dtype: float64
```
> 83.7% 정확도

#### 
