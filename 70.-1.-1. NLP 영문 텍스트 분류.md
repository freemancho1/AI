# NLP - 영문 텍스트 분류

> NLP에서 영문과 한글을 분리하는 이유는,
> * 영문 데이터가 더 풍부하다.
> * 언어의 특성(띄어쓰기, 붙어있는 조사 등) 한글이 전처리 과정에서 상대적으로 어렵다. 

<br/><br/>

# 1. 개요

<br/>

## 1.1. 목표
> 영화 댓글 데이터를 분석해 "긍정" 및 "부정" 평가 여부 분류

<br/>

## 1.2. 작업 순서
> * ⓐ 데이터 불러오기
> * ⓑ 데이터 분석
> * ⓒ 정제되지 않는 데이터의 전처리
> * ⓓ 문제 해결을 위한 알고리즘 모델링

<br/>

## 1.3. 사용할 데이터
> * 데이터 이름 - Bag of Words Meets Bags of Popcon
> * 데이터 내용 - 캐글 대회의 하나인 "워드 팝콘"에 사용된 데이터로 영화의 리뷰로 구성되 있다.
> * 데이터 용도 - 텍스트 분류 학습을 목적으로 사용
> * 데이터 권한 - MIT (캐글 가입후 사용 권장)
> * 데이터 출처 - https://www.kaggle.com/c/word2vec-nlp-tutorial/data

<br/><br/>

# 2. 인공지능 모델링

<br/>

## 2.1. 데이터 다운로드

<br/>

### 2.1.1. kaggle 라이브러리 이용
```python
$ kaggle cometitions download -c word2vec-nlp-tutorial
```
> 대회명이 틀렸나 403에러 발생 <br/>
> 정상적으로 다운되면 4개의 파일이 생성된다.

<br/>

### 2.1.2. 직접 홈페이지에서 다운받기
> 홈페이지에 접속해 대회명을 입력해 다운받을 수 있다.

<br/>

## 2.2. 데이터 불러오기

<br/>

### 2.2.1. 압축 해제
```python
import zipfile

DATA_IN_PATH = '../DATA/word_popcorn/'
file_list = ['labeledTrainData.tsv.zip', 'unlabeledTrainData.tsv.zip', 'testData.tsv.zip']

for file in file_list:
    zipRef = zipfile.ZipFile(DATA_IN_PATH + file, 'r')
    zipRef.extractall(DATA_IN_PATH)
    zipRef.close()
```

<br/>

### 2.2.2. pandas로 읽기
> 파일을 판다스로 읽기 전에 먼저 간단히 파일이 어떻게 생겼는지 확인한다.
```python
$ head labeledTrainData.tsv
```
> header가 있는것을 알 수 있고, 당연히 tsv니 구분자는 tab임을 알 수 있으며, 값들이 큰 따옴표로 엮어 있음을 알 수 있다.

<br/>

```python
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

train_df = pd.read_csv(DATA_IN_PATH+'labeledTrainData.tsv', header=0, delimiter='\t', quoting=3)
# header=0: 첫 번째 줄은 header로 사용한다. 기본값은 infer(추론), header=None는 첫 번째 줄부터 바로 데이터로 활용
# delimiter='\t': 'sep='과 동일함
# quoting=3: 큰 따옴표는 무시
# 자세한 내용은 아래 참조
# print(pd.read_csv.__doc__)
```
<img src="https://user-images.githubusercontent.com/31339365/102861593-45541c00-4473-11eb-9be7-11cd8ffb28ec.png"></img>

<br/>

## 2.3. 데이터 분석

<br/>

### 2.3.1. pandas_profiling으로 분석
```python
import pandas_profiling

train_df_pp = train_df.profile_report()
train_df_pp.to_file('./train_df_pp.html')
```
##### 결과
<img src="https://user-images.githubusercontent.com/31339365/102862211-15594880-4474-11eb-89f8-fb6aa3014f18.png"></img>
> 각 컬럼의 정보, 처음과 끝 데이터 샘플 등 다양한 정보를 볼 수 있다.

<br/>

### 2.3.2. 기본적인 함수로 분석

#### 앞/뒤 데이터 보기
```python
train_df.head()
train_df.tail()
```

#### 파일의 크기 확인
```python
import os

print('파일 크기:')
for file in os.listdir(DATA_IN_PATH):
    if 'tsv' in file:
        print(f'{file.ljust(30)} {str(round(os.path.getsize(DATA_IN_PATH+file)/(1024*1024), 2))} MBytes')

## 결과
# 파일 크기:
# labeledTrainData.tsv           32.0 MBytes
# testData.tsv                   31.21 MBytes
# unlabeledTrainData.tsv         64.16 MBytes
```

#### 학습 데이터 크기 및 각 댓글의 길이 확인
```python
print(f'전체 학습 데이터의 개수: {len(train_df)}')

# 각 댓글의 길이 저장
train_review_length = train_df['review'].apply(len)
train_review_length.head()

## 결과
# 전체 학습 데이터의 개수: 25000
# 0    2304
# 1     948
# 2    2451
# 3    2247
# 4    2233
# Name: review, dtype: int64
```

#### 리뷰 길이 분석
##### 이미지로 분석
```python
plt.figure(figsize=(12,5))
plt.hist(train_review_length, bins=200, alpha=0.3, color='r', label='word')
plt.yscale('log', nonpositive='clip')
plt.title('Log-Histogram of length of review')
plt.xlabel('Length of review')
plt.ylabel('Number of review')
```
<img src="https://user-images.githubusercontent.com/31339365/102867067-8d773c80-447b-11eb-9425-07b0ccec3336.png"></img>

##### 최대/평균/최대 길이 확인
```python
print(f'리뷰 길이 최소값: {np.min(train_review_length)}')
print(f'리뷰 길이 평균값: {np.mean(train_review_length)}')
print(f'리뷰 길이 최대값: {np.max(train_review_length)}')
print(f'리뷰 길이 중앙값: {np.median(train_review_length)}')

## 결과
# 리뷰 길이 최소값: 54
# 리뷰 길이 평균값: 1329.71056
# 리뷰 길이 최대값: 13710
# 리뷰 길이 중앙값: 983.0
```

#### WordCloud
```python
from wordcloud import WordCloud

train_df_cloud = WordCloud(width=1000, height=600).generate(' '.join(train_df['review']))
plt.figure(figsize=(20, 12))
plt.imshow(train_df_cloud)
plt.axis('off')
```
<img src="https://user-images.githubusercontent.com/31339365/102867817-a9c7a900-447c-11eb-9276-0a9a5456cf6e.png"></img>
> 이미지를 보면 "br"이 많이 있는것을 볼 수 있는데, 이는 HTML 태그로 좀 있음 제거된다.
