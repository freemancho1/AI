# Scikit-learn
<br/>

> 사이킷런은 파이썬용 머신러닝 라이브러리로, 머신러닝 기술을 활용하는데 필요한 다양한 기능을 제공한다. <br/>
> 지도학습과 비지도학습 지원, 모델 선택과 평가, 데이터 변환 및 데이터 불러오기, 계산성능 향상 모듈로 구성되어 있다. <br/>

<br/>

> 여기서는 붓꽃 데이터를 이용해 데이터 불러오기, 전처리 및 지도/비지도 학습을 순차적으로 진행한다.

<br/><br/>

## 1. 데이터 전처리
> 붓꽃(Iris) 데이터는 1936년에 만들어진 머신러닝 기초를 공부할 때 가장 많이 사용하는 데이터로써 매우 직관적이고 사용하기 쉽다. <br/><br/>
> **자주 사용하는 데이터 셋**
> * load_iris : 붓꽃 데이터
> * load_boston : 보스톤 집값 데이터
> * load_diabetes : 당뇨병 환자 데이터
> * load_digits : 손글씨 데이터
> * load_linnerud : Multi-output regression용 데이터
> * load_wine : 와인 데이터
> * load_breast_cancer : 위스콘신 유방암 환자 데이터

<br/>

### 1.1. 데이터 불러오기 및 데이터 확인
```python
from sklearn.datasets import load_iris

iris_dataset = load_iris()

print(f'iris_dataset type: {type(iris_dataset)}')
print(f'iris_dataset key: {iris_dataset.keys()}')
print(f'iris_dataset[data] type: {type(iris_dataset["data"])}')

print(f'iris_dataset[data] size: {iris_dataset["data"].shape}')

## 결과
# iris_dataset type: <class 'sklearn.utils.Bunch'>
# iris_dataset key: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])
# iris_dataset[data] type: <class 'numpy.ndarray'>

# iris_dataset[data] size: (150, 4)       
```
> sklearn.utils.Bunch라는 자료구조이며, 이는 다음과 같은 데이터를 가지고 있다.
> * data : 샘플 데이터, Numpy 배열
> * target : Label 데이터, Numpy 배열
> * feature_names : 특성 이름 정보
> * target_names : Label 데이터 이름 정보
> * DESCR : 데이터 설명
> * filename : 다운된 데이터 셋 파일 저장 위치(확장자: csv)

<br/>

### 1.2. 데이터 전처리
> 여기서는 간단히 사이킷런의 사용법에 대해서만 설명할 예정이라 간단히 데이터를 학습과 검증용으로 분리하는 부분만 소개한다.
```python
from sklearn.model_selection import train_test_split
train_data, test_data, train_label, test_label = \      
  train_test_split(iris_dataset['data'], iris_dataset['target'], test_size=0.3, random_state=42)                     

print(f'type train_data: {type(train_data)}')
print(f'train_data.shape: {train_data.shape}, test_data.shape: {test_data.shape}')

## 결과
# type train_data: <class 'numpy.ndarray'>
# train_data.shape: (105, 4), test_data.shape: (45, 4)
```
> 데이터 분리는 train_test_split로 수행하며, 사용방법이 직관적이니 자세한 설명은 생략한다. <br/>
> 참고로, 입력되는 데이터와 라벨은 Numpy 배열이고, random_state는 다른 부분에서 사용하는 seed와 동일한 기능을 수행한다.

<br/><br/>

## 2. 지도학습
> 지도학습에서 사용되는 머신러닝 알고리즘은 다양하기 때문에 알고리즘 선택에 신중해야 한다. <br/>
> 알고리즘은 주어진 데이터의 종류와 인공지능 모델로 하고자하는 일이 무엇인가에 따라 선택하는 대상이 달라진다.<br/>
> 사이킷런에서 추천하는 [올바른 알고리즘 선택을 위한 지도](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)를 참고하기 바란다.

<br/>

### 2.1. 모델 선택 및 학습
> 여기서는 아래 내용을 위 지도에 대입해 "k-최근접 이웃 분류기(k-Nearest Neighbor Classifier)를 선택했다.
> * 선택조건: 데이터 크기 150개, 3개로 분류된 라벨이 있는 데이터를 가지며, 숫자형 데이터이다. <br/>

> 참고로, k-NN을 사용할 때 데이터가 많거나 k값이 커지면 성능에 문제가 있으니 피하는 것이 좋으며, 이 부분도 위 지도를 확인해보면 알 수 있다.
```python
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)           #1
knn.fit(train_data, train_label)                    #2
```
> #1)은 모델을 정의하는 부분으로 "n_neighbors=1"은 가장 가까운 데이터 하나의 값을 그대로 사용한다는 의미이며, 이 값이 3이면 가장 가까운 3개의 값 중에 가장 많이 나오는 값을 선택한다는 의미이다. 3가지 값이 모두 다른 경우 가장 가까운 대상의 값을 취한다. <br/>
> #2)는 학습용 데이터를 이용해 모델을 학습하는 부분이다.

